{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f934f448",
   "metadata": {},
   "source": [
    "**AI Emotion-to-Art ðŸŽ¨ (Team 2)**\n",
    "  **Mohammad Mahdi Omidvar , Arad Chizari , Sogol Tarnabi , Mahyar Alizadeh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70171ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit https://ollama.com/ and install Ollama\n",
    "# Install gemma3:4b model in the terminal using:  ollama run gemma3:4b\n",
    "\n",
    "# Create a virtual environment with Python 3.13.0\n",
    "# Install the following libraries in the environment:\n",
    "# openai-whisper replicate, ollama, base64, gradio \n",
    "\n",
    "# Set your Replicate API token:\n",
    "# REPLICATE_API_TOKEN =Your_Token\n",
    "\n",
    "# If you get a Replicate API token error:\n",
    "# Go to https://replicate.com and create a new token, then set it\n",
    "# Restart VSCode\n",
    "\n",
    "#Please read the ReadMe file for more information on how to run the app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c932ff8d",
   "metadata": {},
   "source": [
    "**Set `REPLICATE_API_TOKEN`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72084f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS: Specified value was saved.\n"
     ]
    }
   ],
   "source": [
    "# !pip install openai-whisper replicate ollama base64 gradio \n",
    "!setx REPLICATE_API_TOKEN Your_Token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8568b4",
   "metadata": {},
   "source": [
    "**Import Libraries:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64468c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\OneDrive\\Main\\Git Hub\\env2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat \n",
    "import base64\n",
    "import replicate\n",
    "import whisper\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f6ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''\n",
    "You are an AI emotion classification system specialized in analyzing text.\n",
    "\n",
    "Your task: Analyze the given text and classify it into exactly ONE of the following emotions:\n",
    "\n",
    "happiness  sadness  anger  fear  surprise  calmnesslove  disgustconfusion  boredomembarrassment  frustrationjealousy  guiltshame  prideanticipation  \n",
    "admirationtrustinterest  reliefcontempt hope hopelessness\n",
    "                                            \n",
    "Rules:  \n",
    "Only return the emotion word exactly as listed above in lowercase.  \n",
    "Do not return explanations, additional text, or punctuation.  \n",
    "If the text contains mixed emotions, choose the dominant emotion.  \n",
    "Be concise and precise.\n",
    "\n",
    "You will receive an input sentence in any language.  \n",
    "Your task is to understand the meaning of the sentence and respond only in English.  \n",
    "Do not translate word-by-word, but convey the full meaning naturally and clearly in English.  \n",
    "Respond concisely and accurately.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af234e",
   "metadata": {},
   "source": [
    "**Generate Art Image from Text Input**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7938562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text(text_user):\n",
    "    stream = chat(\n",
    "        model='gemma3:4b',\n",
    "        messages=[{'role': 'system', 'content': context}, {'role': 'user', 'content': text_user}],\n",
    "        stream=True,\n",
    "    )\n",
    "    text = \"\"\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'])\n",
    "        text += chunk['message']['content']\n",
    "    text = text.strip()\n",
    "\n",
    "    context_text = f\"\"\"\n",
    "    You are an AI system that receives an emotion stored in the variable {text}.  \n",
    "    Your task is to create a clear, creative, and vivid art prompt to generate a painting based on this emotion.  \n",
    "    Do not mention the word {text} literally; instead, convey the emotion through simple atmosphere, setting, and symbolic elements.  \n",
    "    Return only the final prompt in fluent English without any additional explanation.\n",
    "    and finally prompt must be short and concise, not exceeding 20 words.\n",
    "    \"\"\"\n",
    "    stream = chat(\n",
    "        model='gemma3:4b',\n",
    "        messages=[{'role': 'system', 'content': context_text}, {'role': 'user', 'content': text}],\n",
    "        stream=True,\n",
    "    )\n",
    "    make_img_text = \"\"\n",
    "    for chunk in stream:\n",
    "        make_img_text += chunk['message']['content']\n",
    "    make_img_text = make_img_text.strip()\n",
    "\n",
    "    output = replicate.run(\n",
    "        \"google/imagen-4\",\n",
    "        input={\n",
    "            \"prompt\": make_img_text,\n",
    "            \"aspect_ratio\": \"1:1\",\n",
    "            \"output_format\": \"jpg\",\n",
    "            \"safety_filter_level\": \"block_medium_and_above\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return output.url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d1989",
   "metadata": {},
   "source": [
    "**Generate Art Image from Voice Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f65365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_stt(stt_user):\n",
    "    model = whisper.load_model(\"tiny\", device=\"cpu\")\n",
    "    wisper = model.transcribe(stt_user, fp16=False, language=\"en\")['text']\n",
    "\n",
    "    stream = chat(\n",
    "        model='gemma3:4b',\n",
    "        messages=[{'role': 'system', 'content': context}, {'role': 'user', 'content': wisper}],\n",
    "        stream=True,\n",
    "    )\n",
    "    stt = \"\"\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'])\n",
    "        stt += chunk['message']['content']\n",
    "    stt = stt.strip()\n",
    "\n",
    "    context_stt = f\"\"\"\n",
    "    You are an AI system that receives an emotion stored in the variable {stt}.  \n",
    "    Your task is to create a clear, creative, and vivid art prompt to generate a painting based on this emotion.  \n",
    "    Do not mention the word {stt} literally; instead, convey the emotion through simple atmosphere, setting, and symbolic elements.  \n",
    "    Return only the final prompt in fluent English without any additional explanation.\n",
    "    and finally prompt must be short and concise, not exceeding 20 words.\n",
    "    \"\"\"\n",
    "    stream = chat(\n",
    "        model='gemma3:4b',\n",
    "        messages=[{'role': 'system', 'content': context_stt}, {'role': 'user', 'content': stt}],\n",
    "        stream=True,\n",
    "    )\n",
    "    make_img_stt = \"\"\n",
    "    for chunk in stream:\n",
    "        make_img_stt += chunk['message']['content']\n",
    "    make_img_stt = make_img_stt.strip()\n",
    "\n",
    "    output = replicate.run(\n",
    "        \"google/imagen-4\",\n",
    "        input={\n",
    "            \"prompt\": make_img_stt,\n",
    "            \"aspect_ratio\": \"1:1\",\n",
    "            \"output_format\": \"jpg\",\n",
    "            \"safety_filter_level\": \"block_medium_and_above\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return output.url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ba9b6",
   "metadata": {},
   "source": [
    "**Generate Art Image from Image Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f6fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_img(img_user):\n",
    "    with open(img_user, 'rb') as f:\n",
    "        image_data = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    stream = chat(\n",
    "        model='gemma3:4b',\n",
    "        messages=[{'role': 'system', 'content': context}, {'role': 'user', 'content': '', 'images': [image_data]}],\n",
    "        stream=True,\n",
    "    )\n",
    "    img = \"\"\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'])\n",
    "        img += chunk['message']['content']\n",
    "    img = img.strip()\n",
    "\n",
    "    context_img = f\"\"\"\n",
    "    You are an AI system that receives an emotion stored in the variable {img}.  \n",
    "    Your task is to create a clear, creative, and vivid art prompt to generate a painting based on this emotion.  \n",
    "    Do not mention the word {img} literally; instead, convey the emotion through simple atmosphere, setting, and symbolic elements.  \n",
    "    Return only the final prompt in fluent English without any additional explanation.\n",
    "    and finally prompt must be short and concise, not exceeding 20 words.\n",
    "    \"\"\"\n",
    "    stream = chat(\n",
    "        model='gemma3:4b',\n",
    "        messages=[{'role': 'system', 'content': context_img}, {'role': 'user', 'content': img}],\n",
    "        stream=True,\n",
    "    )\n",
    "    make_img_img = \"\"\n",
    "    for chunk in stream:\n",
    "        make_img_img += chunk['message']['content']\n",
    "    make_img_img = make_img_img.strip()\n",
    "\n",
    "    output = replicate.run(\n",
    "        \"google/imagen-4\",\n",
    "        input={\n",
    "            \"prompt\": make_img_img,\n",
    "            \"aspect_ratio\": \"1:1\",\n",
    "            \"output_format\": \"jpg\",\n",
    "            \"safety_filter_level\": \"block_medium_and_above\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return output.url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d495715",
   "metadata": {},
   "source": [
    "**Gradio Interface for AI Emotion-to-Art ðŸŽ¨ (Team 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331928c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hope\n",
      "\n",
      "\n",
      "\n",
      "fr\n",
      "ustration\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## AI Emotion-to-Art ðŸŽ¨ (Team 2) \")\n",
    "\n",
    "    with gr.Tab(\"Text\"):\n",
    "        text_in = gr.Textbox(label=\"Enter your text\")\n",
    "        text_out = gr.Image(label=\"Generated Art\")\n",
    "        text_btn = gr.Button(\"Generate Art\")\n",
    "        text_btn.click(fn=gen_text, inputs=text_in, outputs=text_out)\n",
    "\n",
    "    with gr.Tab(\"Voice\"):\n",
    "        audio_in = gr.Audio(label=\"Upload your voice\", type=\"filepath\")\n",
    "        audio_out = gr.Image(label=\"Generated Art\")\n",
    "        audio_btn = gr.Button(\"Generate Art\")\n",
    "        audio_btn.click(fn=gen_stt, inputs=audio_in, outputs=audio_out)\n",
    "\n",
    "    with gr.Tab(\"Image\"):\n",
    "        img_in = gr.Image(label=\"Upload your image\", type=\"filepath\")\n",
    "        img_out = gr.Image(label=\"Generated Art\")\n",
    "        img_btn = gr.Button(\"Generate Art\")\n",
    "        img_btn.click(fn=gen_img, inputs=img_in, outputs=img_out)\n",
    "\n",
    "demo.launch() # Open the URL "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
